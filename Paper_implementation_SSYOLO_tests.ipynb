{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_X7AC0VJ9CF"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMBepLRDxAJz",
        "outputId": "03c1d49b-cde6-4575-cb02-9ac61bedd633"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (5.3.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.11/dist-packages (from seaborn) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Cloning into 'yolov7'...\n",
            "remote: Enumerating objects: 1197, done.\u001b[K\n",
            "remote: Total 1197 (delta 0), reused 0 (delta 0), pack-reused 1197 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1197/1197), 74.23 MiB | 27.02 MiB/s, done.\n",
            "Resolving deltas: 100% (519/519), done.\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision opencv-python lxml tqdm seaborn\n",
        "!git clone https://github.com/WongKinYiu/yolov7.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rNmCefp0-4Io",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e02b32f-f79a-4ce0-f4a9-a6369692047d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Mount Google Drive (adjust if needed) and copy your NEUDET dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!cp -r /content/drive/MyDrive/NEUDET ./NEUDET\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "gjzy6NcrqW0I",
        "outputId": "3c72958e-29f7-46b4-b33c-7063b111e8a1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './NEUDET/labels'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-112fd99d3ef5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# Scan and filter out corrupted label files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mvalid_label_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './NEUDET/labels'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gPAsGJuV-4L-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "# Directorios según tu dataset copiado\n",
        "annotations_dir = './NEUDET/ANNOTATIONS'\n",
        "labels_dir = './NEUDET/labels'\n",
        "images_dir = './NEUDET/IMAGES'\n",
        "\n",
        "# Crea la carpeta \"labels\" si no existe\n",
        "if not os.path.exists(labels_dir):\n",
        "    os.makedirs(labels_dir)\n",
        "\n",
        "# Define la lista de nombres de clases y un diccionario para mapear el nombre al índice\n",
        "class_names = ['crazing', 'inclusion', 'patches', 'pitted_surface', 'rolled_in_scale', 'scratches']\n",
        "class_map = {name: idx for idx, name in enumerate(class_names)}\n",
        "\n",
        "def convert_annotation(xml_file, img_width=200, img_height=200):\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "    annotation_lines = []\n",
        "    for obj in root.findall('object'):\n",
        "        cls = obj.find('name').text.strip().lower()\n",
        "        if cls not in class_map:\n",
        "            continue  # se ignoran clases desconocidas\n",
        "        cls_id = class_map[cls]\n",
        "        xmlbox = obj.find('bndbox')\n",
        "        xmin = float(xmlbox.find('xmin').text)\n",
        "        ymin = float(xmlbox.find('ymin').text)\n",
        "        xmax = float(xmlbox.find('xmax').text)\n",
        "        ymax = float(xmlbox.find('ymax').text)\n",
        "        # Convertir a formato YOLO (centro x, centro y, ancho, alto), normalizado\n",
        "        x_center = ((xmin + xmax) / 2.0) / img_width\n",
        "        y_center = ((ymin + ymax) / 2.0) / img_height\n",
        "        width = (xmax - xmin) / img_width\n",
        "        height = (ymax - ymin) / img_height\n",
        "        annotation_lines.append(f\"{cls_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\")\n",
        "    return annotation_lines\n",
        "\n",
        "# Procesa cada archivo XML en la carpeta de anotaciones\n",
        "for filename in os.listdir(annotations_dir):\n",
        "    if filename.endswith('.xml'):\n",
        "        xml_path = os.path.join(annotations_dir, filename)\n",
        "        yolo_lines = convert_annotation(xml_path)\n",
        "        # Guarda un archivo .txt con el mismo nombre base que la imagen\n",
        "        base_name = os.path.splitext(filename)[0]\n",
        "        txt_path = os.path.join(labels_dir, base_name + '.txt')\n",
        "        with open(txt_path, 'w') as f:\n",
        "            f.write(\"\\n\".join(yolo_lines))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def is_valid_label_file(file_path):\n",
        "    \"\"\"\n",
        "    Check if a YOLO-format label file is valid.\n",
        "    A valid file has:\n",
        "      - Each non-empty line split into exactly 5 values (class_id, cx, cy, w, h)\n",
        "      - No duplicate bounding boxes (if present)\n",
        "    Empty files (for background images) are considered valid.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r') as f:\n",
        "            lines = [line.strip() for line in f if line.strip()]\n",
        "        # Allow empty label files (interpreted as images with no objects)\n",
        "        if not lines:\n",
        "            return True\n",
        "        boxes = []\n",
        "        for line in lines:\n",
        "            parts = line.split()\n",
        "            if len(parts) != 5:\n",
        "                print(f\"File {file_path} is invalid: line '{line}' does not have 5 values.\")\n",
        "                return False\n",
        "            try:\n",
        "                # Convert each value to float\n",
        "                box = tuple(float(x) for x in parts)\n",
        "            except Exception as e:\n",
        "                print(f\"File {file_path} is invalid: cannot convert line '{line}' to floats.\")\n",
        "                return False\n",
        "            boxes.append(box)\n",
        "        # Check for duplicate boxes\n",
        "        if len(boxes) != len(set(boxes)):\n",
        "            print(f\"File {file_path} is invalid: contains duplicate bounding boxes.\")\n",
        "            return False\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {file_path}: {e}\")\n",
        "        return False\n",
        "\n",
        "# Directory where your label files are stored\n",
        "labels_dir = './NEUDET/labels'\n",
        "\n",
        "# Scan and filter out corrupted label files\n",
        "valid_label_files = []\n",
        "for filename in os.listdir(labels_dir):\n",
        "    if filename.endswith('.txt'):\n",
        "        file_path = os.path.join(labels_dir, filename)\n",
        "        if is_valid_label_file(file_path):\n",
        "            valid_label_files.append(filename)\n",
        "        else:\n",
        "            print(f\"Skipping corrupted label file: {filename}\")\n",
        "\n",
        "print(f\"Found {len(valid_label_files)} valid label files out of {len(os.listdir(labels_dir))}\")\n",
        "\n",
        "# Optionally, if you want to remove the corrupted files from the disk:\n",
        "for filename in os.listdir(labels_dir):\n",
        "    if filename.endswith('.txt'):\n",
        "        file_path = os.path.join(labels_dir, filename)\n",
        "        if not is_valid_label_file(file_path):\n",
        "            os.remove(file_path)\n",
        "            print(f\"Removed corrupted label file: {filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMGNkTOvrLgI",
        "outputId": "eef4ab63-e906-401d-d8f7-0e9e2a4162ca"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File ./NEUDET/labels/inclusion_62.txt is invalid: contains duplicate bounding boxes.\n",
            "Skipping corrupted label file: inclusion_62.txt\n",
            "File ./NEUDET/labels/crazing_120.txt is invalid: contains duplicate bounding boxes.\n",
            "Skipping corrupted label file: crazing_120.txt\n",
            "File ./NEUDET/labels/patches_198.txt is invalid: contains duplicate bounding boxes.\n",
            "Skipping corrupted label file: patches_198.txt\n",
            "Found 1797 valid label files out of 1800\n",
            "File ./NEUDET/labels/inclusion_62.txt is invalid: contains duplicate bounding boxes.\n",
            "Removed corrupted label file: inclusion_62.txt\n",
            "File ./NEUDET/labels/crazing_120.txt is invalid: contains duplicate bounding boxes.\n",
            "Removed corrupted label file: crazing_120.txt\n",
            "File ./NEUDET/labels/patches_198.txt is invalid: contains duplicate bounding boxes.\n",
            "Removed corrupted label file: patches_198.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IBrJiCRH-4Ux"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Rutas de las carpetas originales\n",
        "images_dir = './NEUDET/IMAGES'\n",
        "labels_dir = './NEUDET/labels'\n",
        "output_base = './NEUDET_split'\n",
        "os.makedirs(output_base, exist_ok=True)\n",
        "\n",
        "# Crear las carpetas para train, val y test (imágenes y etiquetas)\n",
        "for phase in ['train', 'val', 'test']:\n",
        "    os.makedirs(os.path.join(output_base, phase, 'images'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(output_base, phase, 'labels'), exist_ok=True)\n",
        "\n",
        "# Lista de archivos de imagen (suponiendo extensión .jpg)\n",
        "image_files = [f for f in os.listdir(images_dir) if f.endswith('.jpg')]\n",
        "random.shuffle(image_files)\n",
        "\n",
        "n = len(image_files)\n",
        "train_split = int(0.8 * n)\n",
        "val_split = int(0.9 * n)\n",
        "\n",
        "train_files = image_files[:train_split]\n",
        "val_files = image_files[train_split:val_split]\n",
        "test_files = image_files[val_split:]\n",
        "\n",
        "def copy_files(file_list, phase):\n",
        "    for file in file_list:\n",
        "        # Copiar la imagen\n",
        "        shutil.copy(os.path.join(images_dir, file),\n",
        "                    os.path.join(output_base, phase, 'images', file))\n",
        "        # Copiar la etiqueta correspondiente (cambiar extensión a .txt)\n",
        "        label_file = os.path.splitext(file)[0] + '.txt'\n",
        "        src_label = os.path.join(labels_dir, label_file)\n",
        "        dst_label = os.path.join(output_base, phase, 'labels', label_file)\n",
        "        if os.path.exists(src_label):\n",
        "            shutil.copy(src_label, dst_label)\n",
        "\n",
        "copy_files(train_files, 'train')\n",
        "copy_files(val_files, 'val')\n",
        "copy_files(test_files, 'test')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VWizDURAJArU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0914e1ea-b893-4b02-bb8a-5c076b3187ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "bash: line 10: fg: no job control\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "cat > yolov7/data/neu_det.yaml << 'EOF'\n",
        "train: NEUDET_split/train/images\n",
        "val: NEUDET_split/val/images\n",
        "test: NEUDET_split/test/images\n",
        "\n",
        "nc: 6\n",
        "names: [crazing, inclusion, patches, pitted_surface, rolled_in_scale, scratches]\n",
        "EOF\n",
        "\n",
        "%%bash\n",
        "# Append custom modules to yolov7/models/common.py\n",
        "cat <<'EOF' >> yolov7/models/common.py\n",
        "\n",
        "# ----- Custom Modules for SS-YOLO -----\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class DWConv(nn.Module):\n",
        "    \"\"\"Depthwise Separable Convolution: depthwise conv + pointwise conv.\"\"\"\n",
        "    def __init__(self, c1, c2, k=3, s=1):\n",
        "        super(DWConv, self).__init__()\n",
        "        self.dw = nn.Conv2d(c1, c1, k, s, k//2, groups=c1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(c1)\n",
        "        self.act1 = nn.ReLU(inplace=True)\n",
        "        self.pw = nn.Conv2d(c1, c2, 1, 1, 0, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(c2)\n",
        "    def forward(self, x):\n",
        "        x = self.act1(self.bn1(self.dw(x)))\n",
        "        x = self.bn2(self.pw(x))\n",
        "        return x\n",
        "\n",
        "class DSimSPPF(nn.Module):\n",
        "    \"\"\"Depthwise-SimSPPF: SPPF module with depthwise conv and ReLU.\"\"\"\n",
        "    def __init__(self, c1, c2, k=5):\n",
        "        super(DSimSPPF, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(c1, c1, 1, 1, 0, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(c1)\n",
        "        self.act1 = nn.ReLU(inplace=True)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=k, stride=1, padding=k//2)\n",
        "        self.conv2 = nn.Conv2d(c1*4, c1*4, 3, 1, 1, groups=c1*4, bias=False)\n",
        "        self.point = nn.Conv2d(c1*4, c2, 1, 1, 0, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(c2)\n",
        "        self.act2 = nn.ReLU(inplace=True)\n",
        "    def forward(self, x):\n",
        "        x = self.act1(self.bn1(self.conv1(x)))\n",
        "        y1 = self.pool(x)\n",
        "        y2 = self.pool(y1)\n",
        "        y3 = self.pool(y2)\n",
        "        y = torch.cat([x, y1, y2, y3], dim=1)\n",
        "        y = self.conv2(y)\n",
        "        y = self.act2(self.bn2(self.point(y)))\n",
        "        return y\n",
        "\n",
        "class SimAM_Module(nn.Module):\n",
        "    \"\"\"SimAM: Simple parameter-free attention module.\"\"\"\n",
        "    def __init__(self, lambda_val=0.1):\n",
        "        super(SimAM_Module, self).__init__()\n",
        "        self.lambda_val = lambda_val\n",
        "    def forward(self, x):\n",
        "        n, c, h, w = x.shape\n",
        "        x_mean = x.mean(dim=[2,3], keepdim=True)\n",
        "        d = (x - x_mean).pow(2)\n",
        "        var = d.sum(dim=[2,3], keepdim=True) / (h*w - 1 + 1e-6)\n",
        "        e_inv = d / (4 * (var + self.lambda_val)) + 0.5\n",
        "        return x * torch.sigmoid(e_inv)\n",
        "EOF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "15mQIZSUH998"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cat > yolov7/cfg/training/ssyolo.yaml <<'EOF'\n",
        "# SS-YOLO model configuration (MobileNetv3 backbone + SimAM + D-SimSPPF)\n",
        "nc: 6\n",
        "depth_multiple: 1.0\n",
        "width_multiple: 1.0\n",
        "\n",
        "anchors:\n",
        "  - [12,16, 19,36, 40,28]   # P3/8\n",
        "  - [36,75, 76,55, 72,146]  # P4/16\n",
        "  - [142,110, 192,243, 459,401]  # P5/32\n",
        "\n",
        "backbone:\n",
        "  # [from, num, module, args]\n",
        "  # Mobilenetv3-large backbone\n",
        "  [[-1, 1, Conv, [16, 3, 2]],          # 0: conv, out 16, stride 2\n",
        "   [-1, 1, Conv, [16, 3, 1]],          # 1: conv, out 16, stride 1\n",
        "   [[-2, -1], 1, Shortcut, [0]],       # 2: residual (16->16)\n",
        "   [-1, 1, Conv, [64, 1, 1]],          # 3: expand 16->64\n",
        "   [-1, 1, DWConv, [24, 3, 2]],        # 4: bottleneck, out 24, stride 2\n",
        "   [-1, 1, Conv, [72, 1, 1]],          # 5: expand 24->72\n",
        "   [-1, 1, DWConv, [24, 3, 1]],        # 6: bottleneck, out 24, stride 1\n",
        "   [[4, -1], 1, Shortcut, [0]],        # 7: residual (24->24)\n",
        "   [-1, 1, Conv, [72, 1, 1]],          # 8: expand 24->72\n",
        "   [-1, 1, DWConv, [40, 5, 2]],        # 9: bottleneck, out 40, stride 2\n",
        "   [-1, 1, Conv, [120, 1, 1]],         # 10: expand 40->120\n",
        "   [-1, 1, DWConv, [40, 5, 1]],        # 11: bottleneck, out 40, stride 1 (SE in MobileNet, skipped)\n",
        "   [[9, -1], 1, Shortcut, [0]],        # 12: residual (40->40)\n",
        "   [-1, 1, Conv, [120, 1, 1]],         # 13: expand 40->120\n",
        "   [-1, 1, DWConv, [40, 5, 1]],        # 14: bottleneck, out 40, stride 1 (SE, skipped)\n",
        "   [[12, -1], 1, Shortcut, [0]],       # 15: residual (40->40)\n",
        "   [-1, 1, Conv, [240, 1, 1]],         # 16: expand 40->240\n",
        "   [-1, 1, DWConv, [80, 3, 2]],        # 17: bottleneck, out 80, stride 2\n",
        "   [-1, 1, Conv, [200, 1, 1]],         # 18: expand 80->200\n",
        "   [-1, 1, DWConv, [80, 3, 1]],        # 19: bottleneck, out 80, stride 1\n",
        "   [[17, -1], 1, Shortcut, [0]],       # 20: residual (80->80)\n",
        "   [-1, 1, Conv, [184, 1, 1]],         # 21: expand 80->184\n",
        "   [-1, 1, DWConv, [80, 3, 1]],        # 22: bottleneck, out 80, stride 1\n",
        "   [[20, -1], 1, Shortcut, [0]],       # 23: residual (80->80)\n",
        "   [-1, 1, Conv, [184, 1, 1]],         # 24: expand 80->184\n",
        "   [-1, 1, DWConv, [80, 3, 1]],        # 25: bottleneck, out 80, stride 1\n",
        "   [[23, -1], 1, Shortcut, [0]],       # 26: residual (80->80)\n",
        "   [-1, 1, Conv, [480, 1, 1]],         # 27: expand 80->480\n",
        "   [-1, 1, DWConv, [112, 3, 1]],       # 28: bottleneck, out 112, stride 1 (no skip, channels diff)\n",
        "   [-1, 1, Conv, [672, 1, 1]],         # 29: expand 112->672\n",
        "   [-1, 1, DWConv, [112, 3, 1]],       # 30: bottleneck, out 112, stride 1\n",
        "   [[28, -1], 1, Shortcut, [0]],       # 31: residual (112->112)\n",
        "   [-1, 1, Conv, [672, 1, 1]],         # 32: expand 112->672\n",
        "   [-1, 1, DWConv, [160, 5, 2]],       # 33: bottleneck, out 160, stride 2\n",
        "   [-1, 1, Conv, [960, 1, 1]],         # 34: expand 160->960\n",
        "   [-1, 1, DWConv, [160, 5, 1]],       # 35: bottleneck, out 160, stride 1 (SE, skipped)\n",
        "   [[33, -1], 1, Shortcut, [0]],       # 36: residual (160->160)\n",
        "   [-1, 1, Conv, [960, 1, 1]],         # 37: expand 160->960\n",
        "   [-1, 1, DWConv, [160, 5, 1]],       # 38: bottleneck, out 160, stride 1 (SE, skipped)\n",
        "   [[36, -1], 1, Shortcut, [0]],       # 39: residual (160->160)\n",
        "   [-1, 1, Conv, [960, 1, 1]]          # 40: 1x1 conv (final backbone output, 960 channels, stride 32)\n",
        "  ]\n",
        "\n",
        "head:\n",
        "  [[40, 1, DSimSPPF, [960, 960, 5]],           # 41: D-SimSPPF on P5 (960->512)\n",
        "   [41, 1, SimAM_Module, [0.1]],       # 42: SimAM attention on P5 feature\n",
        "   [42, 1, Conv, [256, 1, 1]],         # 43: 1x1 conv reduce to 256\n",
        "   [43, 1, nn.Upsample, [None, 2, 'nearest']],  # 44: upsample P5 -> P4 scale\n",
        "   [26, 1, Conv, [256, 1, 1]],         # 45: 1x1 conv on P4 backbone output (80->256)\n",
        "   [[45, 44], 1, Concat, [1]],         # 46: concat P4 and P5-up\n",
        "   [46, 1, Conv, [256, 1, 1]],         # 47: 1x1 conv (256 -> 256)\n",
        "   [46, 1, Conv, [128, 3, 1]],         # 48: 3x3 conv (for feature fusion)\n",
        "   [48, 1, Conv, [128, 3, 1]],         # 49: 3x3 conv\n",
        "   [49, 1, Conv, [128, 1, 1]],         # 50: 1x1 conv (prepare for upsample)\n",
        "   [50, 1, nn.Upsample, [None, 2, 'nearest']],  # 51: upsample to P3\n",
        "   [15, 1, Conv, [128, 1, 1]],         # 52: 1x1 conv on P3 backbone output (40->128)\n",
        "   [[52, 51], 1, Concat, [1]],         # 53: concat P3 and P4-up\n",
        "   [53, 1, Conv, [128, 1, 1]],         # 54: 1x1 conv (128 -> 128)\n",
        "   [53, 1, Conv, [64, 3, 1]],          # 55: 3x3 conv\n",
        "   [55, 1, Conv, [64, 3, 1]],          # 56: 3x3 conv\n",
        "   [56, 1, Conv, [64, 3, 1]],          # 57: 3x3 conv\n",
        "   [57, 1, Conv, [64, 3, 1]],          # 58: 3x3 conv (P3 final feature, 64 channels)\n",
        "   [58, 1, Conv, [128, 1, 1]],         # 59: 1x1 conv (up to 128 for detect)\n",
        "   [59, 1, Conv, [128, 3, 2]],         # 60: downsample P3 to P4 via stride2 conv\n",
        "   [[60, 50], 1, Concat, [1]],         # 61: concat downsampled P3 with P4 feature\n",
        "   [61, 1, Conv, [256, 1, 1]],         # 62: 1x1 conv (256 -> 256)\n",
        "   [62, 1, Conv, [128, 3, 1]],         # 63: 3x3 conv\n",
        "   [63, 1, Conv, [128, 3, 1]],         # 64: 3x3 conv (P4 final feature, 128 ch)\n",
        "   [64, 1, Conv, [256, 3, 2]],         # 65: downsample P4 to P5 via stride2 conv\n",
        "   [[65, 43], 1, Concat, [1]],         # 66: concat downsampled P4 with P5 feature\n",
        "   [66, 1, Conv, [256, 1, 1]],         # 67: 1x1 conv (512->256)\n",
        "   [67, 1, Conv, [128, 3, 1]],         # 68: 3x3 conv\n",
        "   [68, 1, Conv, [128, 3, 1]],         # 69: 3x3 conv (P5 final feature, 128 ch)\n",
        "   [69, 1, SimAM_Module, [0.1]],       # 70: SimAM attention on P5 feature\n",
        "   [[59, 64, 69], 1, IDetect, [nc, anchors]]   # 71: Detect layer (P3, P4, P5)\n",
        "  ]\n",
        "EOF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "IfShqfySAsd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56f00716-9e24-4f97-8e2c-fe101ee0b149"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov7\n",
            "Model(\n",
            "  (model): Sequential(\n",
            "    (0): Conv(\n",
            "      (conv): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU()\n",
            "    )\n",
            "    (1): Conv(\n",
            "      (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU()\n",
            "    )\n",
            "    (2): Shortcut()\n",
            "    (3): Conv(\n",
            "      (conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU()\n",
            "    )\n",
            "    (4): DWConv(\n",
            "      (dw): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act1): ReLU(inplace=True)\n",
            "      (pw): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (5): Conv(\n",
            "      (conv): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU()\n",
            "    )\n",
            "    (6): DWConv(\n",
            "      (dw): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
            "      (bn1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act1): ReLU(inplace=True)\n",
            "      (pw): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (7): Shortcut()\n",
            "    (8): Conv(\n",
            "      (conv): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU()\n",
            "    )\n",
            "    (9): DWConv(\n",
            "      (dw): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
            "      (bn1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act1): ReLU(inplace=True)\n",
            "      (pw): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (10): Conv(\n",
            "      (conv): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU()\n",
            "    )\n",
            "    (11): DWConv(\n",
            "      (dw): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
            "      (bn1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act1): ReLU(inplace=True)\n",
            "      (pw): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (12): Shortcut()\n",
            "    (13): Conv(\n",
            "      (conv): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU()\n",
            "    )\n",
            "    (14): DWConv(\n",
            "      (dw): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
            "      (bn1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act1): ReLU(inplace=True)\n",
            "      (pw): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (15): Shortcut()\n",
            "    (16): Conv(\n",
            "      (conv): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU()\n",
            "    )\n",
            "    (17): DWConv(\n",
            "      (dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
            "      (bn1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act1): ReLU(inplace=True)\n",
            "      (pw): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (18): Conv(\n",
            "      (conv): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU()\n",
            "    )\n",
            "    (19): DWConv(\n",
            "      (dw): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
            "      (bn1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act1): ReLU(inplace=True)\n",
            "      (pw): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (20): Shortcut()\n",
            "    (21): Conv(\n",
            "      (conv): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU()\n",
            "    )\n",
            "    (22): DWConv(\n",
            "      (dw): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
            "      (bn1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act1): ReLU(inplace=True)\n",
            "      (pw): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (23): Shortcut()\n",
            "    (24): Conv(\n",
            "      (conv): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU()\n",
            "    )\n",
            "    (25): DWConv(\n",
            "      (dw): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
            "      (bn1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act1): ReLU(inplace=True)\n",
            "      (pw): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (26): Shortcut()\n",
            "    (27): Conv(\n",
            "      (conv): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU()\n",
            "    )\n",
            "    (28): DWConv(\n",
            "      (dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
            "      (bn1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act1): ReLU(inplace=True)\n",
            "      (pw): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (29): Conv(\n",
            "      (conv): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU()\n",
            "    )\n",
            "    (30): DWConv(\n",
            "      (dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "      (bn1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act1): ReLU(inplace=True)\n",
            "      (pw): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (31): Shortcut()\n",
            "    (32): Conv(\n",
            "      (conv): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU()\n",
            "    )\n",
            "    (33): DWConv(\n",
            "      (dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
            "      (bn1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act1): ReLU(inplace=True)\n",
            "      (pw): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (34): Conv(\n",
            "      (conv): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(960, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU()\n",
            "    )\n",
            "    (35): DWConv(\n",
            "      (dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
            "      (bn1): BatchNorm2d(960, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act1): ReLU(inplace=True)\n",
            "      (pw): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (36): Shortcut()\n",
            "    (37): Conv(\n",
            "      (conv): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(960, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU()\n",
            "    )\n",
            "    (38): DWConv(\n",
            "      (dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
            "      (bn1): BatchNorm2d(960, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act1): ReLU(inplace=True)\n",
            "      (pw): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (39): Shortcut()\n",
            "    (40): Conv(\n",
            "      (conv): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(960, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU()\n",
            "    )\n",
            "    (41): DSimSPPF(\n",
            "      (conv1): Conv2d(960, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(960, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act1): ReLU(inplace=True)\n",
            "      (pool): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
            "      (conv2): Conv2d(3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)\n",
            "      (point): Conv2d(3840, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(960, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act2): ReLU(inplace=True)\n",
            "    )\n",
            "    (42): SimAM_Module()\n",
            "    (43): Conv(\n",
            "      (conv): Conv2d(960, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU()\n",
            "    )\n",
            "    (44): Upsample(scale_factor=2.0, mode='nearest')\n",
            "    (45): Conv(\n",
            "      (conv): Conv2d(80, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU()\n",
            "    )\n",
            "    (46): Concat()\n",
            "    (47): Conv(\n",
            "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU()\n",
            "    )\n",
            "    (48): Conv(\n",
            "      (conv): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU()\n",
            "    )\n",
            "    (49): Conv(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU()\n",
            "    )\n",
            "    (50): Conv(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU()\n",
            "    )\n",
            "    (51): Upsample(scale_factor=2.0, mode='nearest')\n",
            "    (52): Conv(\n",
            "      (conv): Conv2d(40, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU()\n",
            "    )\n",
            "    (53): Concat()\n",
            "    (54): Conv(\n",
            "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU()\n",
            "    )\n",
            "    (55): Conv(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU()\n",
            "    )\n",
            "    (56): Conv(\n",
            "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU()\n",
            "    )\n",
            "    (57): Conv(\n",
            "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU()\n",
            "    )\n",
            "    (58): Conv(\n",
            "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU()\n",
            "    )\n",
            "    (59): Conv(\n",
            "      (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU()\n",
            "    )\n",
            "    (60): Conv(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU()\n",
            "    )\n",
            "    (61): Concat()\n",
            "    (62): Conv(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU()\n",
            "    )\n",
            "    (63): Conv(\n",
            "      (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU()\n",
            "    )\n",
            "    (64): Conv(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU()\n",
            "    )\n",
            "    (65): Conv(\n",
            "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU()\n",
            "    )\n",
            "    (66): Concat()\n",
            "    (67): Conv(\n",
            "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU()\n",
            "    )\n",
            "    (68): Conv(\n",
            "      (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU()\n",
            "    )\n",
            "    (69): Conv(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU()\n",
            "    )\n",
            "    (70): SimAM_Module()\n",
            "    (71): IDetect(\n",
            "      (m): ModuleList(\n",
            "        (0-2): 3 x Conv2d(128, 33, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "      (ia): ModuleList(\n",
            "        (0-2): 3 x ImplicitA()\n",
            "      )\n",
            "      (im): ModuleList(\n",
            "        (0-2): 3 x ImplicitM()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "# Cell 7: Verify model architecture\n",
        "%cd yolov7\n",
        "from models.yolo import Model\n",
        "model = Model(\"cfg/training/ssyolo.yaml\", ch=1, nc=6)  # ch=1 for grayscale images; change if necessary\n",
        "print(model)\n",
        "%cd ..\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_z6T6rqeAsgp"
      },
      "outputs": [],
      "source": [
        "# Cell 8: (Optional) Set WANDB offline mode to avoid wandb prompts\n",
        "import os\n",
        "os.environ['WANDB_MODE'] = 'offline'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "1GHAsxBBAslW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fccd5fb-111d-4a6a-be68-f0a9d692d277"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov7\n",
            "--2025-04-05 19:54:25--  https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt\n",
            "Resolving github.com (github.com)... 140.82.116.3\n",
            "Connecting to github.com (github.com)|140.82.116.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/b0243edf-9fb0-4337-95e1-42555f1b37cf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250405%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250405T195425Z&X-Amz-Expires=300&X-Amz-Signature=77ed60c0ce509dd3411cc47cf6d70f17fb55e932434a3ee2b5fa0b733f2da970&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov7.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-04-05 19:54:25--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/b0243edf-9fb0-4337-95e1-42555f1b37cf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250405%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250405T195425Z&X-Amz-Expires=300&X-Amz-Signature=77ed60c0ce509dd3411cc47cf6d70f17fb55e932434a3ee2b5fa0b733f2da970&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov7.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 75587165 (72M) [application/octet-stream]\n",
            "Saving to: ‘yolov7.pt’\n",
            "\n",
            "yolov7.pt           100%[===================>]  72.08M   117MB/s    in 0.6s    \n",
            "\n",
            "2025-04-05 19:54:26 (117 MB/s) - ‘yolov7.pt’ saved [75587165/75587165]\n",
            "\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content/yolov7\n",
        "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt\n",
        "%cd /content\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python yolov7/train.py --device 0 --epochs 300 --batch-size 16 \\\n",
        "  --weights \"/content/yolov7/yolov7.pt\" \\\n",
        "  --cfg yolov7/cfg/training/ssyolo.yaml \\\n",
        "  --data yolov7/data/neu_det.yaml --name ss_yolo_run\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0reX8qGPhORp",
        "outputId": "54fb5998-ac9a-40bc-a5f8-a52eef6649d3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-05 19:54:36.992235: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1743882877.013010    7358 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1743882877.019566    7358 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-05 19:54:37.041112: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "YOLOR 🚀 v0.1-128-ga207844 torch 2.6.0+cu124 CUDA:0 (Tesla T4, 15095.0625MB)\n",
            "\n",
            "Namespace(weights='/content/yolov7/yolov7.pt', cfg='yolov7/cfg/training/ssyolo.yaml', data='yolov7/data/neu_det.yaml', hyp='./yolov7/data/hyp.scratch.p5.yaml', epochs=300, batch_size=16, img_size=[640, 640], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='0', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=8, project='runs/train', entity=None, name='ss_yolo_run', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', freeze=[0], v5_metric=False, world_size=1, global_rank=-1, save_dir='runs/train/ss_yolo_run2', total_batch_size=16)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.0, paste_in=0.15, loss_ota=1\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov7/train.py\", line 616, in <module>\n",
            "    train(hyp, opt, device, tb_writer)\n",
            "  File \"/content/yolov7/train.py\", line 71, in train\n",
            "    run_id = torch.load(weights, map_location=device).get('wandb_id') if weights.endswith('.pt') and os.path.isfile(weights) else None\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/serialization.py\", line 1470, in load\n",
            "    raise pickle.UnpicklingError(_get_wo_message(str(e))) from None\n",
            "_pickle.UnpicklingError: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n",
            "\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n",
            "\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n",
            "\tWeightsUnpickler error: Unsupported global: GLOBAL models.yolo.Model was not an allowed global by default. Please use `torch.serialization.add_safe_globals([Model])` or the `torch.serialization.safe_globals([Model])` context manager to allowlist this global if you trust this class/function.\n",
            "\n",
            "Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For CUDA 11.8, for instance:\n",
        "!pip install --upgrade --force-reinstall torch==2.0.1+cu118 torchvision==0.15.2+cu118 \\\n",
        "    --extra-index-url https://download.pytorch.org/whl/cu118\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HR0ATxL7hgcg",
        "outputId": "b63cf3e1-8d79-4578-e6a6-3172256cf7d7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu118\n",
            "Collecting torch==2.0.1+cu118\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.0.1%2Bcu118-cp311-cp311-linux_x86_64.whl (2267.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m463.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.15.2+cu118\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.15.2%2Bcu118-cp311-cp311-linux_x86_64.whl (6.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filelock (from torch==2.0.1+cu118)\n",
            "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting typing-extensions (from torch==2.0.1+cu118)\n",
            "  Downloading typing_extensions-4.13.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting sympy (from torch==2.0.1+cu118)\n",
            "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch==2.0.1+cu118)\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch==2.0.1+cu118)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0.1+cu118)\n",
            "  Downloading https://download.pytorch.org/whl/triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy (from torchvision==0.15.2+cu118)\n",
            "  Downloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests (from torchvision==0.15.2+cu118)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.15.2+cu118)\n",
            "  Downloading pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting cmake (from triton==2.0.0->torch==2.0.1+cu118)\n",
            "  Downloading cmake-4.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.1+cu118)\n",
            "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.0.1+cu118)\n",
            "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests->torchvision==0.15.2+cu118)\n",
            "  Downloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->torchvision==0.15.2+cu118)\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->torchvision==0.15.2+cu118)\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->torchvision==0.15.2+cu118)\n",
            "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.0.1+cu118)\n",
            "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m101.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.13.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.9/143.9 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cmake-4.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mpmath, lit, urllib3, typing-extensions, sympy, pillow, numpy, networkx, MarkupSafe, idna, filelock, cmake, charset-normalizer, certifi, requests, jinja2, triton, torch, torchvision\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.3.0\n",
            "    Uninstalling urllib3-2.3.0:\n",
            "      Successfully uninstalled urllib3-2.3.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.13.0\n",
            "    Uninstalling typing_extensions-4.13.0:\n",
            "      Successfully uninstalled typing_extensions-4.13.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.1.0\n",
            "    Uninstalling pillow-11.1.0:\n",
            "      Successfully uninstalled pillow-11.1.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.18.0\n",
            "    Uninstalling filelock-3.18.0:\n",
            "      Successfully uninstalled filelock-3.18.0\n",
            "  Attempting uninstall: cmake\n",
            "    Found existing installation: cmake 3.31.6\n",
            "    Uninstalling cmake-3.31.6:\n",
            "      Successfully uninstalled cmake-3.31.6\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.1\n",
            "    Uninstalling charset-normalizer-3.4.1:\n",
            "      Successfully uninstalled charset-normalizer-3.4.1\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.1.31\n",
            "    Uninstalling certifi-2025.1.31:\n",
            "      Successfully uninstalled certifi-2025.1.31\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.4 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.4 which is incompatible.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.0.1+cu118 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 certifi-2025.1.31 charset-normalizer-3.4.1 cmake-4.0.0 filelock-3.18.0 idna-3.10 jinja2-3.1.6 lit-18.1.8 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.4 pillow-11.1.0 requests-2.32.3 sympy-1.13.3 torch-2.0.1+cu118 torchvision-0.15.2+cu118 triton-2.0.0 typing-extensions-4.13.1 urllib3-2.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "certifi",
                  "charset_normalizer",
                  "mpmath",
                  "requests",
                  "sympy",
                  "torch",
                  "torchgen",
                  "torchvision",
                  "triton"
                ]
              },
              "id": "0cef652766fe475a9b126d625dca88e3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python yolov7/train.py --device 0 --epochs 300 --batch-size 16 \\\n",
        "  --weights /content/yolov7/yolov7.pt \\\n",
        "  --cfg yolov7/cfg/training/ssyolo.yaml \\\n",
        "  --data yolov7/data/neu_det.yaml --name ss_yolo_run\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5EzVVlEh-GA",
        "outputId": "8d62d265-0d4c-4f34-df3d-142aee57fc83"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-05 20:00:04.104819: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1743883204.124970    8801 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1743883204.131087    8801 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-05 20:00:04.153776: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.2.4 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"/content/yolov7/train.py\", line 24, in <module>\n",
            "    import test  # import test.py to get mAP after each epoch\n",
            "  File \"/content/yolov7/test.py\", line 12, in <module>\n",
            "    from models.experimental import attempt_load\n",
            "  File \"/content/yolov7/models/experimental.py\", line 6, in <module>\n",
            "    from models.common import Conv, DWConv\n",
            "  File \"/content/yolov7/models/common.py\", line 11, in <module>\n",
            "    from torchvision.ops import DeformConv2d\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/__init__.py\", line 6, in <module>\n",
            "    from torchvision import datasets, io, models, ops, transforms, utils\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/models/__init__.py\", line 17, in <module>\n",
            "    from . import detection, optical_flow, quantization, segmentation, video\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/models/detection/__init__.py\", line 1, in <module>\n",
            "    from .faster_rcnn import *\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/models/detection/faster_rcnn.py\", line 16, in <module>\n",
            "    from .anchor_utils import AnchorGenerator\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/models/detection/anchor_utils.py\", line 10, in <module>\n",
            "    class AnchorGenerator(nn.Module):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/models/detection/anchor_utils.py\", line 63, in AnchorGenerator\n",
            "    device: torch.device = torch.device(\"cpu\"),\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/detection/anchor_utils.py:63: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(\"cpu\"),\n",
            "YOLOR 🚀 v0.1-128-ga207844 torch 2.0.1+cu118 CUDA:0 (Tesla T4, 15095.0625MB)\n",
            "\n",
            "Namespace(weights='/content/yolov7/yolov7.pt', cfg='yolov7/cfg/training/ssyolo.yaml', data='yolov7/data/neu_det.yaml', hyp='./yolov7/data/hyp.scratch.p5.yaml', epochs=300, batch_size=16, img_size=[640, 640], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='0', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=8, project='runs/train', entity=None, name='ss_yolo_run', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', freeze=[0], v5_metric=False, world_size=1, global_rank=-1, save_dir='runs/train/ss_yolo_run3', total_batch_size=16)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.0, paste_in=0.15, loss_ota=1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m `resume` will be ignored since W&B syncing is set to `offline`. Starting a new run with run id pqgmjqr0.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       464  models.common.Conv                      [3, 16, 3, 2]                 \n",
            "  1                -1  1      2336  models.common.Conv                      [16, 16, 3, 1]                \n",
            "  2          [-2, -1]  1         0  models.common.Shortcut                  [0]                           \n",
            "  3                -1  1      1152  models.common.Conv                      [16, 64, 1, 1]                \n",
            "  4                -1  1      2288  models.common.DWConv                    [64, 24, 3, 2]                \n",
            "  5                -1  1      1872  models.common.Conv                      [24, 72, 1, 1]                \n",
            "  6                -1  1      2568  models.common.DWConv                    [72, 24, 3, 1]                \n",
            "  7           [4, -1]  1         0  models.common.Shortcut                  [0]                           \n",
            "  8                -1  1      1872  models.common.Conv                      [24, 72, 1, 1]                \n",
            "  9                -1  1      4904  models.common.DWConv                    [72, 40, 5, 2]                \n",
            " 10                -1  1      5040  models.common.Conv                      [40, 120, 1, 1]               \n",
            " 11                -1  1      8120  models.common.DWConv                    [120, 40, 5, 1]               \n",
            " 12           [9, -1]  1         0  models.common.Shortcut                  [0]                           \n",
            " 13                -1  1      5040  models.common.Conv                      [40, 120, 1, 1]               \n",
            " 14                -1  1      8120  models.common.DWConv                    [120, 40, 5, 1]               \n",
            " 15          [12, -1]  1         0  models.common.Shortcut                  [0]                           \n",
            " 16                -1  1     10080  models.common.Conv                      [40, 240, 1, 1]               \n",
            " 17                -1  1     22000  models.common.DWConv                    [240, 80, 3, 2]               \n",
            " 18                -1  1     16400  models.common.Conv                      [80, 200, 1, 1]               \n",
            " 19                -1  1     18360  models.common.DWConv                    [200, 80, 3, 1]               \n",
            " 20          [17, -1]  1         0  models.common.Shortcut                  [0]                           \n",
            " 21                -1  1     15088  models.common.Conv                      [80, 184, 1, 1]               \n",
            " 22                -1  1     16904  models.common.DWConv                    [184, 80, 3, 1]               \n",
            " 23          [20, -1]  1         0  models.common.Shortcut                  [0]                           \n",
            " 24                -1  1     15088  models.common.Conv                      [80, 184, 1, 1]               \n",
            " 25                -1  1     16904  models.common.DWConv                    [184, 80, 3, 1]               \n",
            " 26          [23, -1]  1         0  models.common.Shortcut                  [0]                           \n",
            " 27                -1  1     39360  models.common.Conv                      [80, 480, 1, 1]               \n",
            " 28                -1  1     59264  models.common.DWConv                    [480, 112, 3, 1]              \n",
            " 29                -1  1     76608  models.common.Conv                      [112, 672, 1, 1]              \n",
            " 30                -1  1     82880  models.common.DWConv                    [672, 112, 3, 1]              \n",
            " 31          [28, -1]  1         0  models.common.Shortcut                  [0]                           \n",
            " 32                -1  1     76608  models.common.Conv                      [112, 672, 1, 1]              \n",
            " 33                -1  1    125984  models.common.DWConv                    [672, 160, 5, 2]              \n",
            " 34                -1  1    155520  models.common.Conv                      [160, 960, 1, 1]              \n",
            " 35                -1  1    179840  models.common.DWConv                    [960, 160, 5, 1]              \n",
            " 36          [33, -1]  1         0  models.common.Shortcut                  [0]                           \n",
            " 37                -1  1    155520  models.common.Conv                      [160, 960, 1, 1]              \n",
            " 38                -1  1    179840  models.common.DWConv                    [960, 160, 5, 1]              \n",
            " 39          [36, -1]  1         0  models.common.Shortcut                  [0]                           \n",
            " 40                -1  1    155520  models.common.Conv                      [160, 960, 1, 1]              \n",
            " 41                40  1   4646400  models.common.DSimSPPF                  [960, 960, 5]                 \n",
            " 42                41  1         0  models.common.SimAM_Module              [0.1]                         \n",
            " 43                42  1    246272  models.common.Conv                      [960, 256, 1, 1]              \n",
            " 44                43  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 45                26  1     20992  models.common.Conv                      [80, 256, 1, 1]               \n",
            " 46          [45, 44]  1         0  models.common.Concat                    [1]                           \n",
            " 47                46  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 48                46  1    590080  models.common.Conv                      [512, 128, 3, 1]              \n",
            " 49                48  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 50                49  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 51                50  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 52                15  1      5376  models.common.Conv                      [40, 128, 1, 1]               \n",
            " 53          [52, 51]  1         0  models.common.Concat                    [1]                           \n",
            " 54                53  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 55                53  1    147584  models.common.Conv                      [256, 64, 3, 1]               \n",
            " 56                55  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 57                56  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 58                57  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 59                58  1      8448  models.common.Conv                      [64, 128, 1, 1]               \n",
            " 60                59  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 61          [60, 50]  1         0  models.common.Concat                    [1]                           \n",
            " 62                61  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 63                62  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 64                63  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 65                64  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            " 66          [65, 43]  1         0  models.common.Concat                    [1]                           \n",
            " 67                66  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 68                67  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 69                68  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 70                69  1         0  models.common.SimAM_Module              [0.1]                         \n",
            " 71      [59, 64, 69]  1     13254  models.yolo.IDetect                     [6, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [128, 128, 128]]\n",
            "Model Summary: 278 layers, 9106414 parameters, 9106414 gradients\n",
            "\n",
            "Transferred 63/423 items from /content/yolov7/yolov7.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 71 .bias, 72 conv.weight, 74 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'NEUDET_split/train/labels' images and labels... 14 found, 0 missing, 0 empty, 0 corrupted:   1% 14/1440 [00:00<00:10, 138.72it/s]\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label NEUDET_split/train/images/crazing_120.jpg: duplicate labels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'NEUDET_split/train/labels' images and labels... 378 found, 0 missing, 0 empty, 1 corrupted:  26% 378/1440 [00:00<00:01, 662.62it/s]\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label NEUDET_split/train/images/inclusion_62.jpg: duplicate labels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'NEUDET_split/train/labels' images and labels... 532 found, 0 missing, 0 empty, 2 corrupted:  37% 532/1440 [00:00<00:01, 721.61it/s]\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label NEUDET_split/train/images/patches_198.jpg: duplicate labels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'NEUDET_split/train/labels' images and labels... 1440 found, 0 missing, 241 empty, 3 corrupted: 100% 1440/1440 [00:01<00:00, 995.24it/s] \n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: NEUDET_split/train/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'NEUDET_split/val/labels' images and labels... 180 found, 0 missing, 29 empty, 0 corrupted: 100% 180/180 [00:00<00:00, 704.67it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: NEUDET_split/val/labels.cache\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov7/train.py\", line 616, in <module>\n",
            "    train(hyp, opt, device, tb_writer)\n",
            "  File \"/content/yolov7/train.py\", line 262, in train\n",
            "    c = torch.tensor(labels[:, 0])  # classes\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Could not infer dtype of numpy.float32\n",
            "\u001b[1;34mwandb\u001b[0m: \n",
            "\u001b[1;34mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[1;34mwandb\u001b[0m: \u001b[1mwandb sync /content/wandb/offline-run-20250405_200016-pqgmjqr0\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/offline-run-20250405_200016-pqgmjqr0/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python yolov7/train.py --device 0 --epochs 300 --batch-size 16 \\\n",
        "  --weights '' --cfg yolov7/cfg/training/ssyolo.yaml \\\n",
        "  --data yolov7/data/neu_det.yaml --name ssyolo_scratch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYxBe7pBi8ba",
        "outputId": "7bcf850d-7b67-4d64-98f7-fa0939320b63"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-05 20:02:19.310082: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1743883339.331899    9434 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1743883339.338257    9434 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-05 20:02:19.360211: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.2.4 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"/content/yolov7/train.py\", line 24, in <module>\n",
            "    import test  # import test.py to get mAP after each epoch\n",
            "  File \"/content/yolov7/test.py\", line 12, in <module>\n",
            "    from models.experimental import attempt_load\n",
            "  File \"/content/yolov7/models/experimental.py\", line 6, in <module>\n",
            "    from models.common import Conv, DWConv\n",
            "  File \"/content/yolov7/models/common.py\", line 11, in <module>\n",
            "    from torchvision.ops import DeformConv2d\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/__init__.py\", line 6, in <module>\n",
            "    from torchvision import datasets, io, models, ops, transforms, utils\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/models/__init__.py\", line 17, in <module>\n",
            "    from . import detection, optical_flow, quantization, segmentation, video\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/models/detection/__init__.py\", line 1, in <module>\n",
            "    from .faster_rcnn import *\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/models/detection/faster_rcnn.py\", line 16, in <module>\n",
            "    from .anchor_utils import AnchorGenerator\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/models/detection/anchor_utils.py\", line 10, in <module>\n",
            "    class AnchorGenerator(nn.Module):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/models/detection/anchor_utils.py\", line 63, in AnchorGenerator\n",
            "    device: torch.device = torch.device(\"cpu\"),\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/detection/anchor_utils.py:63: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(\"cpu\"),\n",
            "YOLOR 🚀 v0.1-128-ga207844 torch 2.0.1+cu118 CUDA:0 (Tesla T4, 15095.0625MB)\n",
            "\n",
            "Namespace(weights='', cfg='yolov7/cfg/training/ssyolo.yaml', data='yolov7/data/neu_det.yaml', hyp='./yolov7/data/hyp.scratch.p5.yaml', epochs=300, batch_size=16, img_size=[640, 640], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='0', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=8, project='runs/train', entity=None, name='ssyolo_scratch', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', freeze=[0], v5_metric=False, world_size=1, global_rank=-1, save_dir='runs/train/ssyolo_scratch', total_batch_size=16)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.0, paste_in=0.15, loss_ota=1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m `resume` will be ignored since W&B syncing is set to `offline`. Starting a new run with run id 0cqctapx.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       464  models.common.Conv                      [3, 16, 3, 2]                 \n",
            "  1                -1  1      2336  models.common.Conv                      [16, 16, 3, 1]                \n",
            "  2          [-2, -1]  1         0  models.common.Shortcut                  [0]                           \n",
            "  3                -1  1      1152  models.common.Conv                      [16, 64, 1, 1]                \n",
            "  4                -1  1      2288  models.common.DWConv                    [64, 24, 3, 2]                \n",
            "  5                -1  1      1872  models.common.Conv                      [24, 72, 1, 1]                \n",
            "  6                -1  1      2568  models.common.DWConv                    [72, 24, 3, 1]                \n",
            "  7           [4, -1]  1         0  models.common.Shortcut                  [0]                           \n",
            "  8                -1  1      1872  models.common.Conv                      [24, 72, 1, 1]                \n",
            "  9                -1  1      4904  models.common.DWConv                    [72, 40, 5, 2]                \n",
            " 10                -1  1      5040  models.common.Conv                      [40, 120, 1, 1]               \n",
            " 11                -1  1      8120  models.common.DWConv                    [120, 40, 5, 1]               \n",
            " 12           [9, -1]  1         0  models.common.Shortcut                  [0]                           \n",
            " 13                -1  1      5040  models.common.Conv                      [40, 120, 1, 1]               \n",
            " 14                -1  1      8120  models.common.DWConv                    [120, 40, 5, 1]               \n",
            " 15          [12, -1]  1         0  models.common.Shortcut                  [0]                           \n",
            " 16                -1  1     10080  models.common.Conv                      [40, 240, 1, 1]               \n",
            " 17                -1  1     22000  models.common.DWConv                    [240, 80, 3, 2]               \n",
            " 18                -1  1     16400  models.common.Conv                      [80, 200, 1, 1]               \n",
            " 19                -1  1     18360  models.common.DWConv                    [200, 80, 3, 1]               \n",
            " 20          [17, -1]  1         0  models.common.Shortcut                  [0]                           \n",
            " 21                -1  1     15088  models.common.Conv                      [80, 184, 1, 1]               \n",
            " 22                -1  1     16904  models.common.DWConv                    [184, 80, 3, 1]               \n",
            " 23          [20, -1]  1         0  models.common.Shortcut                  [0]                           \n",
            " 24                -1  1     15088  models.common.Conv                      [80, 184, 1, 1]               \n",
            " 25                -1  1     16904  models.common.DWConv                    [184, 80, 3, 1]               \n",
            " 26          [23, -1]  1         0  models.common.Shortcut                  [0]                           \n",
            " 27                -1  1     39360  models.common.Conv                      [80, 480, 1, 1]               \n",
            " 28                -1  1     59264  models.common.DWConv                    [480, 112, 3, 1]              \n",
            " 29                -1  1     76608  models.common.Conv                      [112, 672, 1, 1]              \n",
            " 30                -1  1     82880  models.common.DWConv                    [672, 112, 3, 1]              \n",
            " 31          [28, -1]  1         0  models.common.Shortcut                  [0]                           \n",
            " 32                -1  1     76608  models.common.Conv                      [112, 672, 1, 1]              \n",
            " 33                -1  1    125984  models.common.DWConv                    [672, 160, 5, 2]              \n",
            " 34                -1  1    155520  models.common.Conv                      [160, 960, 1, 1]              \n",
            " 35                -1  1    179840  models.common.DWConv                    [960, 160, 5, 1]              \n",
            " 36          [33, -1]  1         0  models.common.Shortcut                  [0]                           \n",
            " 37                -1  1    155520  models.common.Conv                      [160, 960, 1, 1]              \n",
            " 38                -1  1    179840  models.common.DWConv                    [960, 160, 5, 1]              \n",
            " 39          [36, -1]  1         0  models.common.Shortcut                  [0]                           \n",
            " 40                -1  1    155520  models.common.Conv                      [160, 960, 1, 1]              \n",
            " 41                40  1   4646400  models.common.DSimSPPF                  [960, 960, 5]                 \n",
            " 42                41  1         0  models.common.SimAM_Module              [0.1]                         \n",
            " 43                42  1    246272  models.common.Conv                      [960, 256, 1, 1]              \n",
            " 44                43  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 45                26  1     20992  models.common.Conv                      [80, 256, 1, 1]               \n",
            " 46          [45, 44]  1         0  models.common.Concat                    [1]                           \n",
            " 47                46  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 48                46  1    590080  models.common.Conv                      [512, 128, 3, 1]              \n",
            " 49                48  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 50                49  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 51                50  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 52                15  1      5376  models.common.Conv                      [40, 128, 1, 1]               \n",
            " 53          [52, 51]  1         0  models.common.Concat                    [1]                           \n",
            " 54                53  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 55                53  1    147584  models.common.Conv                      [256, 64, 3, 1]               \n",
            " 56                55  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 57                56  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 58                57  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 59                58  1      8448  models.common.Conv                      [64, 128, 1, 1]               \n",
            " 60                59  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 61          [60, 50]  1         0  models.common.Concat                    [1]                           \n",
            " 62                61  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 63                62  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 64                63  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 65                64  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            " 66          [65, 43]  1         0  models.common.Concat                    [1]                           \n",
            " 67                66  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 68                67  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 69                68  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 70                69  1         0  models.common.SimAM_Module              [0.1]                         \n",
            " 71      [59, 64, 69]  1     13254  models.yolo.IDetect                     [6, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [128, 128, 128]]\n",
            "Model Summary: 278 layers, 9106414 parameters, 9106414 gradients\n",
            "\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 71 .bias, 72 conv.weight, 74 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'NEUDET_split/train/labels.cache' images and labels... 1440 found, 0 missing, 241 empty, 3 corrupted: 100% 1440/1440 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'NEUDET_split/val/labels.cache' images and labels... 180 found, 0 missing, 29 empty, 0 corrupted: 100% 180/180 [00:00<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov7/train.py\", line 616, in <module>\n",
            "    train(hyp, opt, device, tb_writer)\n",
            "  File \"/content/yolov7/train.py\", line 262, in train\n",
            "    c = torch.tensor(labels[:, 0])  # classes\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Could not infer dtype of numpy.float32\n",
            "\u001b[1;34mwandb\u001b[0m: \n",
            "\u001b[1;34mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[1;34mwandb\u001b[0m: \u001b[1mwandb sync /content/wandb/offline-run-20250405_200228-0cqctapx\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/offline-run-20250405_200228-0cqctapx/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python yolov7/train.py --device 0 --epochs 300 --batch-size 16 \\\n",
        "  --weights '' --cfg yolov7/cfg/training/ssyolo.yaml \\\n",
        "  --data yolov7/data/neu_det.yaml --name ssyolo_scratch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_b2fatS0rZmN",
        "outputId": "914efa0b-f420-48cf-c34a-cabd73c800e9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/yolov7/train.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}